{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-plot\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6sCj3itO-QT",
        "outputId": "9efe47a4-f20b-41c3-aeb7-bef60b1eb38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.10.1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (8.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.22.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (23.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCVY25ojNvpa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "import scikitplot\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, GlobalMaxPool2D\n",
        "from tensorflow.keras.layers import TimeDistributed, LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4mpxtSTPuDt",
        "outputId": "8699d328-a6cf-46ab-f0c5-d8a59ab8c58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/proj/train'\n",
        "test_dir = '/content/drive/MyDrive/proj/test'"
      ],
      "metadata": {
        "id": "w-TkorBPPzud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row, col = 48, 48\n",
        "classes = 7"
      ],
      "metadata": {
        "id": "y5sfGESmQY1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_exp(path, set_):\n",
        "    dict_ = {}\n",
        "    for expression in os.listdir(path):\n",
        "        dir_ = path + expression\n",
        "        dict_[expression] = len(dir_)\n",
        "    df = pd.DataFrame(dict_, index=[set_])\n",
        "    return df\n",
        "train_count = count_exp(train_dir, 'train')\n",
        "test_count = count_exp(test_dir, 'test')\n",
        "print(train_count)\n",
        "print(test_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6q_zpHeQkhU",
        "outputId": "0a248fa9-1497-4edf-afb0-0ca37fde8eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       sad  disgust  fear  angry  happy  surprise  neutral  laugh.jpg\n",
            "train   36       40    37     38     38        41       40         42\n",
            "      surprise  happy  disgust  fear  neutral  angry  sad\n",
            "test        40     37       39    36       39     37   35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   zoom_range=0.3,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(train_dir,\n",
        "                                                batch_size=64,\n",
        "                                                target_size=(48,48),\n",
        "                                                shuffle=True,\n",
        "                                                color_mode='grayscale',\n",
        "                                                class_mode='categorical')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory(test_dir,\n",
        "                                                batch_size=64,\n",
        "                                                target_size=(48,48),\n",
        "                                                shuffle=True,\n",
        "                                                color_mode='grayscale',\n",
        "                                                class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7qi02iMYuTM",
        "outputId": "220a28a9-631e-41fc-c9b2-46a923335b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la2-X_9SYuZL",
        "outputId": "e14908ab-1122-44e6-d72e-72dc7b5f7f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'angry': 0,\n",
              " 'disgust': 1,\n",
              " 'fear': 2,\n",
              " 'happy': 3,\n",
              " 'neutral': 4,\n",
              " 'sad': 5,\n",
              " 'surprise': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dcnn(input_shape, show_arch=True):\n",
        "    net = Sequential(name='DCNN')\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(3,3),\n",
        "            input_shape=input_shape,\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_1'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_1'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_2'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_2'))\n",
        "    \n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n",
        "    net.add(Dropout(0.45, name='dropout_1'))\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=128,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_3'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_3'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=128,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_4'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_4'))\n",
        "    \n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n",
        "    net.add(Dropout(0.45, name='dropout_2'))\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=256,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_5'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_5'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=256,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_6'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_6'))\n",
        "    \n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n",
        "    net.add(Dropout(0.4, name='dropout_3'))\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=512,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_7'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_7'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=512,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_8'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_8'))\n",
        "    \n",
        "    net.add(Dropout(0.4, name='dropout_4'))\n",
        "    \n",
        "    net.add(GlobalMaxPool2D(name=\"globalmax2d\"))\n",
        "    \n",
        "    if show_arch:\n",
        "        net.summary()\n",
        "    \n",
        "    return net"
      ],
      "metadata": {
        "id": "uupkM8BmZ93P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def memory_model(input_shape, num_class, show_arch=True):\n",
        "    dcnn = build_dcnn(input_shape[1:], show_arch=False)\n",
        "    \n",
        "    model = Sequential(name=\"convolutional_Bidrectional_LSTM\")\n",
        "\n",
        "    model.add(\n",
        "        TimeDistributed(\n",
        "            dcnn,\n",
        "            input_shape=input_shape,\n",
        "            name=\"time_distributed\",\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True, name=\"bidirect_lstm_1\")))\n",
        "    model.add(Dropout(.35, name=\"dropout_1\"))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=False, name=\"bidirect_lstm_2\")))\n",
        "    model.add(Dropout(.45, name=\"dropout_2\"))\n",
        "\n",
        "    model.add(\n",
        "        Dense(\n",
        "            128,\n",
        "            activation='elu',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='dense_1'\n",
        "        )\n",
        "    )\n",
        "    model.add(BatchNormalization(name='batchnorm_1'))\n",
        "    model.add(Dropout(.7, name=\"dropout_3\"))\n",
        "\n",
        "    model.add(\n",
        "        Dense(\n",
        "            num_class,\n",
        "            activation='softmax',\n",
        "            name='out_layer'\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    if show_arch:\n",
        "        model.summary()\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "UVazG0trZ953"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.8,\n",
        "    patience=7,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    lr_scheduler,\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "mz4M7EuvZ981"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = (3, 48, 48, 1)\n",
        "optim = optimizers.Nadam(0.001)\n",
        "\n",
        "model = memory_model(INPUT_SHAPE, num_class=7)\n",
        "model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=optim,\n",
        "        metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r90nauz4Z9_H",
        "outputId": "55321fec-802f-4a18-c45c-194a9c4d3183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"convolutional_Bidrectional_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDistr  (None, 3, 512)           4691904   \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 3, 256)           656384    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3, 256)            0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              164352    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " batchnorm_1 (BatchNormaliza  (None, 128)              512       \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,530,567\n",
            "Trainable params: 5,526,471\n",
            "Non-trainable params: 4,096\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-52Mxf2ioY0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = training_set.n // training_set.batch_size\n",
        "validation_steps = test_set.n // test_set.batch_size\n",
        "\n",
        "hist = model.fit(x=training_set,\n",
        "                 validation_data=test_set,\n",
        "                 epochs=30,\n",
        "                 callbacks=callbacks,\n",
        "                 steps_per_epoch=50,\n",
        "                 validation_steps=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlF22xazZ-A9",
        "outputId": "bf63754b-b488-4f96-8e6d-4be342a211f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "50/50 [==============================] - 1270s 25s/step - loss: nan - accuracy: 0.1344 - val_loss: nan - val_accuracy: 0.1306 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 936s 19s/step - loss: nan - accuracy: 0.1350 - val_loss: nan - val_accuracy: 0.1303 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 681s 14s/step - loss: nan - accuracy: 0.1488 - val_loss: nan - val_accuracy: 0.1403 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 564s 11s/step - loss: nan - accuracy: 0.1416 - val_loss: nan - val_accuracy: 0.1319 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 455s 9s/step - loss: nan - accuracy: 0.1327 - val_loss: nan - val_accuracy: 0.1344 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 371s 7s/step - loss: nan - accuracy: 0.1287 - val_loss: nan - val_accuracy: 0.1338 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 317s 6s/step - loss: nan - accuracy: 0.1322 - val_loss: nan - val_accuracy: 0.1319 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 281s 6s/step - loss: nan - accuracy: 0.1488 - val_loss: nan - val_accuracy: 0.1256 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 279s 6s/step - loss: nan - accuracy: 0.1333 - val_loss: nan - val_accuracy: 0.1353 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1331\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "50/50 [==============================] - 249s 5s/step - loss: nan - accuracy: 0.1331 - val_loss: nan - val_accuracy: 0.1347 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 201s 4s/step - loss: nan - accuracy: 0.1355 - val_loss: nan - val_accuracy: 0.1347 - lr: 8.0000e-04\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 196s 4s/step - loss: nan - accuracy: 0.1316 - val_loss: nan - val_accuracy: 0.1462 - lr: 8.0000e-04\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 168s 3s/step - loss: nan - accuracy: 0.1434 - val_loss: nan - val_accuracy: 0.1334 - lr: 8.0000e-04\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 158s 3s/step - loss: nan - accuracy: 0.1481 - val_loss: nan - val_accuracy: 0.1372 - lr: 8.0000e-04\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 142s 3s/step - loss: nan - accuracy: 0.1341 - val_loss: nan - val_accuracy: 0.1331 - lr: 8.0000e-04\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 137s 3s/step - loss: nan - accuracy: 0.1341 - val_loss: nan - val_accuracy: 0.1372 - lr: 8.0000e-04\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 130s 3s/step - loss: nan - accuracy: 0.1331 - val_loss: nan - val_accuracy: 0.1331 - lr: 8.0000e-04\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 126s 3s/step - loss: nan - accuracy: 0.1462 - val_loss: nan - val_accuracy: 0.1278 - lr: 8.0000e-04\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1387\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "50/50 [==============================] - 125s 2s/step - loss: nan - accuracy: 0.1387 - val_loss: nan - val_accuracy: 0.1297 - lr: 8.0000e-04\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 121s 2s/step - loss: nan - accuracy: 0.1444 - val_loss: nan - val_accuracy: 0.1312 - lr: 6.4000e-04\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 143s 3s/step - loss: nan - accuracy: 0.1409 - val_loss: nan - val_accuracy: 0.1294 - lr: 6.4000e-04\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 120s 2s/step - loss: nan - accuracy: 0.1365 - val_loss: nan - val_accuracy: 0.1300 - lr: 6.4000e-04\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 119s 2s/step - loss: nan - accuracy: 0.1328 - val_loss: nan - val_accuracy: 0.1297 - lr: 6.4000e-04\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 121s 2s/step - loss: nan - accuracy: 0.1434 - val_loss: nan - val_accuracy: 0.1312 - lr: 6.4000e-04\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 121s 2s/step - loss: nan - accuracy: 0.1331 - val_loss: nan - val_accuracy: 0.1306 - lr: 6.4000e-04\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1412\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "50/50 [==============================] - 124s 2s/step - loss: nan - accuracy: 0.1412 - val_loss: nan - val_accuracy: 0.1341 - lr: 6.4000e-04\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 122s 2s/step - loss: nan - accuracy: 0.1491 - val_loss: nan - val_accuracy: 0.1331 - lr: 5.1200e-04\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 121s 2s/step - loss: nan - accuracy: 0.1513 - val_loss: nan - val_accuracy: 0.1338 - lr: 5.1200e-04\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 120s 2s/step - loss: nan - accuracy: 0.1388 - val_loss: nan - val_accuracy: 0.1375 - lr: 5.1200e-04\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 124s 2s/step - loss: nan - accuracy: 0.1431 - val_loss: nan - val_accuracy: 0.1350 - lr: 5.1200e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UcHQaVhDZ-D3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}